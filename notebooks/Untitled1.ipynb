{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d881d10-8b10-46ec-b101-9387e963accb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2.0 in /opt/conda/lib/python3.11/site-packages (1.24.4)\n",
      "Requirement already satisfied: scikit-learn<1.4 in /opt/conda/lib/python3.11/site-packages (1.3.1)\n",
      "Requirement already satisfied: scipy<1.12 in /opt/conda/lib/python3.11/site-packages (1.11.3)\n",
      "Requirement already satisfied: imbalanced-learn<0.13 in /opt/conda/lib/python3.11/site-packages (0.12.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from scikit-learn<1.4) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn<1.4) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"numpy<2.0\" \"scikit-learn<1.4\" \"scipy<1.12\" \"imbalanced-learn<0.13\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "644ed199-f7ba-48fe-b115-e1bce05d878b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectando no Postgres em: postgresql://mluser:mlpass@postgres:5432/mldb\n",
      "Shape da base: (307, 13)\n",
      "Colunas: ['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes', 'ejection_fraction', 'high_blood_pressure', 'platelets', 'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time', 'DEATH_EVENT']\n",
      "Shape X: (307, 12)\n",
      "Shape y: (307,)\n",
      "Treino: (214, 12) Teste: (93, 12)\n",
      "Ap√≥s SMOTE:\n",
      "Distribui√ß√£o de y_train_smote: {0: 142, 1: 142}\n",
      "MLflow tracking URI: http://mlflow:5000\n",
      "Experimento: <Experiment: artifact_location='mlflow-artifacts:/2', creation_time=1764719532557, experiment_id='2', last_update_time=1764719532557, lifecycle_stage='active', name='meu_experimento_trendz', tags={}>\n",
      "\n",
      "=== M√©tricas RF + SMOTE (modelo final) ===\n",
      "Accuracy : 0.8602150537634409\n",
      "Precision: 0.8275862068965517\n",
      "Recall   : 0.75\n",
      "F1-score : 0.7868852459016394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/03 13:57:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'meu_modelo_trendz' already exists. Creating a new version of this model...\n",
      "2025/12/03 13:57:18 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: meu_modelo_trendz, version 11\n",
      "Created version '11' of model 'meu_modelo_trendz'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run ID: 2d5e082a032242bcb9bb8b1ef4ff3627\n",
      "üèÉ View run RF_SMOTE_modelo_final at: http://mlflow:5000/#/experiments/2/runs/2d5e082a032242bcb9bb8b1ef4ff3627\n",
      "üß™ View experiment at: http://mlflow:5000/#/experiments/2\n",
      "\n",
      "‚úÖ Modelo + m√©tricas + CSV + gr√°ficos enviados para o MLflow!\n",
      "Abra http://localhost:5000:\n",
      " - Veja params/metrics na vis√£o do run;\n",
      " - Em Artifacts: tabelas/, plots/ e model/.\n",
      "No Model Registry, promova `meu_modelo_trendz` para `Production` para o mlflow-serving usar.\n",
      "\n",
      "Enviando vers√£o 1 (run_id=1d6ee8b7f0ec4c228ae97fa85cbaaeab) para ThingsBoard:\n",
      "{'version': 1, 'run_id': '1d6ee8b7f0ec4c228ae97fa85cbaaeab', 'accuracy': 0.8688524590163934, 'precision': 0.875, 'recall': 0.7, 'f1_score': 0.7777777777777777, 'n_estimators': 200, 'max_depth': 5}\n",
      "Resposta TB: 200 \n",
      "\n",
      "Enviando vers√£o 2 (run_id=212dc7f320f54a9da8a80333b5e56baf) para ThingsBoard:\n",
      "{'version': 2, 'run_id': '212dc7f320f54a9da8a80333b5e56baf', 'accuracy': 0.8688524590163934, 'precision': 0.875, 'recall': 0.7, 'f1_score': 0.7777777777777777, 'n_estimators': 200, 'max_depth': 5}\n",
      "Resposta TB: 200 \n",
      "\n",
      "Enviando vers√£o 3 (run_id=04ec83dbff0d4cd88c92a5b06826bfd6) para ThingsBoard:\n",
      "{'version': 3, 'run_id': '04ec83dbff0d4cd88c92a5b06826bfd6', 'accuracy': 0.8688524590163934, 'precision': 0.875, 'recall': 0.7, 'f1_score': 0.7777777777777777, 'n_estimators': 200, 'max_depth': 5}\n",
      "Resposta TB: 200 \n",
      "\n",
      "Enviando vers√£o 4 (run_id=435978dba87a4812a40d65aadd7145c4) para ThingsBoard:\n",
      "{'version': 4, 'run_id': '435978dba87a4812a40d65aadd7145c4', 'accuracy': 0.8688524590163934, 'precision': 0.875, 'recall': 0.7, 'f1_score': 0.7777777777777777, 'n_estimators': 200, 'max_depth': 5}\n",
      "Resposta TB: 200 \n",
      "\n",
      "Enviando vers√£o 5 (run_id=01b0f9d5e2d04216bcab92c3df72dda2) para ThingsBoard:\n",
      "{'version': 5, 'run_id': '01b0f9d5e2d04216bcab92c3df72dda2', 'accuracy': 0.8688524590163934, 'precision': 0.875, 'recall': 0.7, 'f1_score': 0.7777777777777777, 'n_estimators': 200, 'max_depth': 5}\n",
      "Resposta TB: 200 \n",
      "\n",
      "Enviando vers√£o 6 (run_id=ad8570c5788144e0a5634ca18a5dcf80) para ThingsBoard:\n",
      "{'version': 6, 'run_id': 'ad8570c5788144e0a5634ca18a5dcf80', 'accuracy': 0.8524590163934426, 'precision': 0.8235294117647058, 'recall': 0.7, 'f1_score': 0.7567567567567567, 'n_estimators': 200, 'max_depth': 3}\n",
      "Resposta TB: 200 \n",
      "\n",
      "Enviando vers√£o 7 (run_id=1bbb85391ee64accb7cfac562d15fc10) para ThingsBoard:\n",
      "{'version': 7, 'run_id': '1bbb85391ee64accb7cfac562d15fc10', 'accuracy': 0.8571428571428571, 'precision': 0.7931034482758621, 'recall': 0.7666666666666667, 'f1_score': 0.7796610169491527, 'n_estimators': 200, 'max_depth': 3}\n",
      "Resposta TB: 200 \n",
      "\n",
      "Enviando vers√£o 8 (run_id=92451ca2988142b2829bfd75ef1f167c) para ThingsBoard:\n",
      "{'version': 8, 'run_id': '92451ca2988142b2829bfd75ef1f167c', 'accuracy': 0.8571428571428571, 'precision': 0.7931034482758621, 'recall': 0.7666666666666667, 'f1_score': 0.7796610169491527, 'n_estimators': 200, 'max_depth': 3}\n",
      "Resposta TB: 200 \n",
      "\n",
      "Enviando vers√£o 9 (run_id=c6520a82f543456184b5ffe416d2bcbc) para ThingsBoard:\n",
      "{'version': 9, 'run_id': 'c6520a82f543456184b5ffe416d2bcbc', 'accuracy': 0.8478260869565217, 'precision': 0.8148148148148148, 'recall': 0.7096774193548387, 'f1_score': 0.7586206896551724, 'n_estimators': 200, 'max_depth': 3}\n",
      "Resposta TB: 200 \n",
      "\n",
      "Enviando vers√£o 10 (run_id=7fc0ac7c432b499e8c8aa1eb7330f917) para ThingsBoard:\n",
      "{'version': 10, 'run_id': '7fc0ac7c432b499e8c8aa1eb7330f917', 'accuracy': 0.8478260869565217, 'precision': 0.8148148148148148, 'recall': 0.7096774193548387, 'f1_score': 0.7586206896551724, 'n_estimators': 200, 'max_depth': 3}\n",
      "Resposta TB: 200 \n",
      "\n",
      "Enviando vers√£o 11 (run_id=2d5e082a032242bcb9bb8b1ef4ff3627) para ThingsBoard:\n",
      "{'version': 11, 'run_id': '2d5e082a032242bcb9bb8b1ef4ff3627', 'accuracy': 0.8602150537634409, 'precision': 0.8275862068965517, 'recall': 0.75, 'f1_score': 0.7868852459016394, 'n_estimators': 200, 'max_depth': 3}\n",
      "Resposta TB: 200 \n"
     ]
    }
   ],
   "source": [
    "# Se ainda n√£o instalou essas vers√µes no container, rode UMA vez:\n",
    "\n",
    "# ============================================\n",
    "# 0. IMPORTS\n",
    "# ============================================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 1. CONEX√ÉO COM POSTGRES (SEU \"SNOWFLAKE\" LOCAL)\n",
    "# ============================================\n",
    "\n",
    "DB_USER = os.getenv(\"DB_USER\", \"mluser\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\", \"mlpass\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\", \"postgres\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\", \"5432\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"mldb\")\n",
    "\n",
    "db_url = f\"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "print(\"Conectando no Postgres em:\", db_url)\n",
    "\n",
    "# ============================================\n",
    "# 2. LER OS DADOS DA TABELA\n",
    "# ============================================\n",
    "\n",
    "TABLE_NAME = \"dados_analise\"\n",
    "\n",
    "df = pd.read_sql(f'SELECT * FROM \"{TABLE_NAME}\"', engine)\n",
    "\n",
    "print(\"Shape da base:\", df.shape)\n",
    "print(\"Colunas:\", df.columns.tolist())\n",
    "\n",
    "# ============================================\n",
    "# 3. DEFINIR FEATURES E TARGET\n",
    "# ============================================\n",
    "\n",
    "TARGET_COL = \"DEATH_EVENT\"\n",
    "\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(\n",
    "        f'A coluna alvo \"{TARGET_COL}\" n√£o existe na tabela. '\n",
    "        f\"Ajuste TARGET_COL para uma das colunas: {df.columns.tolist()}\"\n",
    "    )\n",
    "\n",
    "df = df.dropna(subset=[TARGET_COL])\n",
    "\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "# tira colunas que n√£o s√£o features (se n√£o existirem, ignora)\n",
    "drop_cols = [TARGET_COL, \"device_name\", \"ts\", \"id\"]\n",
    "drop_cols_present = [c for c in drop_cols if c in df.columns]\n",
    "X = df.drop(columns=drop_cols_present)\n",
    "\n",
    "print(\"Shape X:\", X.shape)\n",
    "print(\"Shape y:\", y.shape)\n",
    "\n",
    "# ============================================\n",
    "# 4. TRAIN / TEST SPLIT\n",
    "# ============================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Treino:\", X_train.shape, \"Teste:\", X_test.shape)\n",
    "\n",
    "# ============================================\n",
    "# 5. SCALER + SMOTE\n",
    "# ============================================\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote_scaled, y_train_smote = smote.fit_resample(\n",
    "    X_train_scaled, y_train\n",
    ")\n",
    "\n",
    "print(\"Ap√≥s SMOTE:\")\n",
    "(unique, counts) = np.unique(y_train_smote, return_counts=True)\n",
    "print(\"Distribui√ß√£o de y_train_smote:\", dict(zip(unique, counts)))\n",
    "\n",
    "# ============================================\n",
    "# 6. CONFIGURA√á√ÉO DO MLFLOW\n",
    "# ============================================\n",
    "\n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\", \"http://mlflow:5000\")\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "EXPERIMENT_NAME = \"meu_experimento_trendz\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# garante que n√£o tem run antigo aberto\n",
    "mlflow.end_run()\n",
    "\n",
    "print(\"MLflow tracking URI:\", mlflow.get_tracking_uri())\n",
    "print(\"Experimento:\", mlflow.get_experiment_by_name(EXPERIMENT_NAME))\n",
    "\n",
    "# ============================================\n",
    "# 7. TREINAR MODELO FINAL (RandomForest + SMOTE)\n",
    "# ============================================\n",
    "\n",
    "rf_final = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=3,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "rf_final.fit(X_train_smote_scaled, y_train_smote)\n",
    "y_pred = rf_final.predict(X_test_scaled)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "print(\"\\n=== M√©tricas RF + SMOTE (modelo final) ===\")\n",
    "print(\"Accuracy :\", acc)\n",
    "print(\"Precision:\", prec)\n",
    "print(\"Recall   :\", rec)\n",
    "print(\"F1-score :\", f1)\n",
    "\n",
    "# ============================================\n",
    "# 8. ENVIAR PARA O MLFLOW (PARAMS + M√âTRICAS +\n",
    "#    CSV + GR√ÅFICOS + MODELO)\n",
    "# ============================================\n",
    "\n",
    "with mlflow.start_run(run_name=\"RF_SMOTE_modelo_final\") as run:\n",
    "    # -------- Par√¢metros --------\n",
    "    mlflow.log_param(\"algoritmo\", \"RandomForestClassifier\")\n",
    "    mlflow.log_param(\"oversampling\", \"SMOTE\")\n",
    "    mlflow.log_param(\"n_estimators\", rf_final.n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", rf_final.max_depth)\n",
    "    mlflow.log_param(\"class_weight\", \"balanced\")\n",
    "    mlflow.log_param(\"n_features\", X_train_smote_scaled.shape[1])\n",
    "    mlflow.log_param(\"tabela_origem\", TABLE_NAME)\n",
    "    mlflow.log_param(\"target_col\", TARGET_COL)\n",
    "\n",
    "    # -------- M√©tricas --------\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"precision\", prec)\n",
    "    mlflow.log_metric(\"recall\", rec)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    \n",
    "    # -------- 8.0. CSV de avalia√ß√£o --------\n",
    "    eval_df = pd.DataFrame({\n",
    "        \"y_true\": y_test.values,\n",
    "        \"y_pred\": y_pred\n",
    "    })\n",
    "    eval_dir = \"eval\"\n",
    "    os.makedirs(eval_dir, exist_ok=True)\n",
    "    eval_csv_path = os.path.join(eval_dir, \"y_true_y_pred.csv\")\n",
    "    eval_df.to_csv(eval_csv_path, index=False)\n",
    "    \n",
    "    mlflow.log_artifact(eval_csv_path, artifact_path=\"tabelas\")\n",
    "\n",
    "    # -------- 8.1. Matriz de confus√£o (PNG) --------\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig_cm, ax_cm = plt.subplots()\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(ax=ax_cm)\n",
    "    ax_cm.set_title(\"Matriz de confus√£o\")\n",
    "    fig_cm.tight_layout()\n",
    "\n",
    "    mlflow.log_figure(fig_cm, \"plots/confusion_matrix.png\")\n",
    "    plt.close(fig_cm)\n",
    "\n",
    "    # -------- 8.2. Import√¢ncia das features (PNG) --------\n",
    "    feature_names = list(X.columns)\n",
    "    importances = rf_final.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    fig_imp, ax_imp = plt.subplots(figsize=(8, 5))\n",
    "    ax_imp.bar(range(len(importances)), importances[indices])\n",
    "    ax_imp.set_xticks(range(len(importances)))\n",
    "    ax_imp.set_xticklabels(\n",
    "        [feature_names[i] for i in indices],\n",
    "        rotation=90\n",
    "    )\n",
    "    ax_imp.set_title(\"Import√¢ncia das features\")\n",
    "    ax_imp.set_ylabel(\"Import√¢ncia relativa\")\n",
    "    fig_imp.tight_layout()\n",
    "\n",
    "    mlflow.log_figure(fig_imp, \"plots/feature_importance.png\")\n",
    "    plt.close(fig_imp)\n",
    "    \n",
    "    # -------- 8.3. Modelo (artefato principal) --------\n",
    "    signature = infer_signature(\n",
    "        X_train_smote_scaled,\n",
    "        rf_final.predict(X_train_smote_scaled)\n",
    "    )\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "        rf_final,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        registered_model_name=\"meu_modelo_trendz\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nRun ID:\", run.info.run_id)\n",
    "\n",
    "print(\"\\n‚úÖ Modelo + m√©tricas + CSV + gr√°ficos enviados para o MLflow!\")\n",
    "print(\"Abra http://localhost:5000:\")\n",
    "print(\" - Veja params/metrics na vis√£o do run;\")\n",
    "print(\" - Em Artifacts: tabelas/, plots/ e model/.\")\n",
    "print(\"No Model Registry, promova `meu_modelo_trendz` para `Production` para o mlflow-serving usar.\")\n",
    "\n",
    "\n",
    "\n",
    "    # -------- 9. enviando para o tb -------\n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\", \"http://mlflow:5000\")\n",
    "MODEL_NAME = os.getenv(\"MLFLOW_MODEL_NAME\", \"meu_modelo_trendz\")\n",
    "\n",
    "TB_BASE_URL = os.getenv(\"TB_BASE_URL\", \"http://thingsboard:9090\")\n",
    "\n",
    "TB_TOKEN = os.getenv(\"TB_METRICS_TOKEN\", \"7QQlaAIt0eWGk91MGhlN\")\n",
    "\n",
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "versions = client.search_model_versions(f\"name='{MODEL_NAME}'\")\n",
    "\n",
    "for mv in sorted(versions, key=lambda v: int(v.version)):\n",
    "    run_id = mv.run_id\n",
    "    version = int(mv.version)\n",
    "\n",
    "    run = client.get_run(run_id)\n",
    "    metrics = run.data.metrics\n",
    "    params = run.data.params\n",
    "\n",
    "    acc = metrics.get(\"accuracy\")\n",
    "    prec = metrics.get(\"precision\")\n",
    "    rec = metrics.get(\"recall\")\n",
    "    f1 = metrics.get(\"f1_score\")\n",
    "\n",
    "    n_estimators = params.get(\"n_estimators\")\n",
    "    max_depth = params.get(\"max_depth\")\n",
    "\n",
    "    payload = {\n",
    "        \"version\": version,\n",
    "        \"run_id\": run_id,\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1_score\": f1,\n",
    "    }\n",
    "\n",
    "    if n_estimators is not None:\n",
    "        try:\n",
    "            payload[\"n_estimators\"] = int(n_estimators)\n",
    "        except ValueError:\n",
    "            payload[\"n_estimators\"] = n_estimators\n",
    "\n",
    "    if max_depth is not None:\n",
    "        try:\n",
    "            payload[\"max_depth\"] = int(max_depth)\n",
    "        except ValueError:\n",
    "            payload[\"max_depth\"] = max_depth\n",
    "\n",
    "    payload = {k: v for k, v in payload.items() if v is not None}\n",
    "\n",
    "    print(f\"\\nEnviando vers√£o {version} (run_id={run_id}) para ThingsBoard:\")\n",
    "    print(payload)\n",
    "\n",
    "    try:\n",
    "        resp = requests.post(\n",
    "            f\"{TB_BASE_URL}/api/v1/{TB_TOKEN}/telemetry\",\n",
    "            json=payload,\n",
    "            timeout=5,\n",
    "        )\n",
    "        print(\"Resposta TB:\", resp.status_code, resp.text)\n",
    "    except Exception as e:\n",
    "        print(\"Erro ao enviar para TB:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf343ee-d1a2-4f95-b883-6a753120e361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
